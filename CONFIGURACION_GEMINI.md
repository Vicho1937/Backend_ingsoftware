# ü§ñ Configuraci√≥n del Chatbot con Gemini - Gu√≠a Completa

## ‚úÖ **Estado Actual**

**‚úÖ Chatbot configurado y funcionando con Google Gemini (100% GRATIS)**

- ‚úÖ Google Generative AI instalado (`google-generativeai==0.8.5`)
- ‚úÖ Modelo: `gemini-2.5-flash` (√∫ltimo modelo gratuito de Google)
- ‚úÖ Integraci√≥n completa en backend Django
- ‚úÖ Frontend actualizado con endpoint correcto
- ‚úÖ Sistema de sesiones funcionando
- ‚úÖ Historial de conversaciones guardado en base de datos
- ‚úÖ Restricci√≥n de contexto (solo rutas locales)

---

## üÜì **¬øPor qu√© Gemini?**

### **Ventajas sobre OpenAI:**
- ‚úÖ **100% GRATIS** - Sin necesidad de tarjeta de cr√©dito
- ‚úÖ **Sin l√≠mites de cuota** - Llamadas ilimitadas dentro de los rate limits
- ‚úÖ **Modelo avanzado** - Gemini 2.5 Flash es uno de los modelos m√°s recientes
- ‚úÖ **Multimodal** - Soporta texto, im√°genes, audio y video
- ‚úÖ **R√°pido** - Latencia muy baja en respuestas
- ‚úÖ **API simple** - F√°cil de usar y mantener

### **Rate Limits (Plan Gratuito):**
- 15 requests por minuto (RPM)
- 1 mill√≥n de tokens por minuto (TPM)
- 1,500 requests por d√≠a (RPD)

**Para el proyecto de Rutas Locales, estos l√≠mites son m√°s que suficientes.**

---

## üîë **Configuraci√≥n Actual**

### **1. API Key en `.env`:**
```env
GEMINI_API_KEY=AIzaSyDeSGpw8EpEhKum3hNfO3yhOt5IXGl9a9o
```

### **2. Configuraci√≥n en `settings.py`:**
```python
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY', '')
```

### **3. C√≥digo del Chatbot (`chatbot/views.py`):**
```python
import google.generativeai as genai

# En la vista chat_message:
genai.configure(api_key=settings.GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-2.5-flash')

full_prompt = f"{system_prompt}\n\nUsuario: {user_message}\n\nAsistente:"
response = model.generate_content(full_prompt)

bot_response = response.text
```

---

## üöÄ **C√≥mo Obtener una API Key de Gemini**

### **Paso a Paso:**

1. **Ve a Google AI Studio:**
   - URL: https://aistudio.google.com/app/apikey

2. **Inicia sesi√≥n con tu cuenta de Google**
   - Usa cualquier cuenta de Gmail

3. **Crear API Key:**
   - Click en **"Get API Key"** o **"Create API Key"**
   - Selecciona tu proyecto de Google Cloud (o crea uno nuevo)
   - La key se genera instant√°neamente

4. **Copiar la Key:**
   - Formato: `AIzaSy...` (39 caracteres)
   - Gu√°rdala en un lugar seguro

5. **Agregar al `.env`:**
   ```env
   GEMINI_API_KEY=tu-key-aqui
   ```

**‚ö†Ô∏è Importante:**
- No compartas tu API key con nadie
- No la subas a GitHub (ya est√° en `.gitignore`)
- Puedes regenerarla en cualquier momento si se compromete

---

## üìä **Modelos Disponibles (Gratuitos)**

### **Recomendados para Chat:**

| Modelo | Descripci√≥n | Velocidad | Calidad |
|--------|-------------|-----------|---------|
| `gemini-2.5-flash` | **‚≠ê Recomendado** - √öltimo modelo, r√°pido y preciso | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê |
| `gemini-2.5-pro` | M√°s potente, respuestas m√°s elaboradas | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| `gemini-2.0-flash` | Versi√≥n anterior, muy estable | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê |
| `gemini-flash-latest` | Siempre apunta al √∫ltimo modelo flash | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê |

### **Actualmente usando:** `gemini-2.5-flash`

---

## üß™ **Probar el Chatbot**

### **1. Desde la l√≠nea de comandos:**
```bash
python test_gemini_chatbot.py
```

Este script verifica:
- ‚úÖ API Key configurada correctamente
- ‚úÖ Conexi√≥n con Gemini
- ‚úÖ Modelos disponibles
- ‚úÖ Generaci√≥n de respuestas

### **2. Desde el frontend:**
1. Inicia el backend:
   ```bash
   python manage.py runserver
   ```

2. Inicia el frontend:
   ```bash
   cd frontend
   npm run dev
   ```

3. Ve a: http://localhost:5173/chat
4. Inicia sesi√≥n si es necesario
5. ¬°Prueba el chatbot!

### **3. Con curl (API directa):**
```bash
curl -X POST http://localhost:8000/api/chatbot/message/ \
  -H "Content-Type: application/json" \
  -d "{\"message\": \"Hola, ¬øqu√© lugares puedo visitar?\"}"
```

---

## üìù **Estructura del Proyecto**

### **Backend:**
```
chatbot/
‚îú‚îÄ‚îÄ models.py          # Modelo ChatHistory
‚îú‚îÄ‚îÄ views.py           # L√≥gica del chatbot con Gemini
‚îú‚îÄ‚îÄ serializers.py     # Serializadores
‚îî‚îÄ‚îÄ urls.py            # Endpoints: /message/, /history/
```

### **Frontend:**
```
src/
‚îî‚îÄ‚îÄ pages/
    ‚îî‚îÄ‚îÄ Chat.jsx       # Interfaz del chatbot
```

### **Configuraci√≥n:**
```
.env                   # GEMINI_API_KEY
settings.py            # Configuraci√≥n Django
requirements.txt       # Dependencias (google-generativeai)
```

---

## üé® **Personalizaci√≥n del Chatbot**

### **System Prompt Actual:**
```python
system_prompt = """Eres un asistente virtual especializado en la plataforma de Rutas Locales.
Tu funci√≥n es ayudar a los usuarios a descubrir y obtener informaci√≥n sobre lugares locales, 
restaurantes, atracciones tur√≠sticas, y negocios de la zona.

IMPORTANTE: Solo debes responder preguntas relacionadas con:
- Informaci√≥n sobre rutas y lugares locales
- C√≥mo usar la plataforma
- Recomendaciones de lugares
- Caracter√≠sticas de la aplicaci√≥n
- Ayuda para navegar por la plataforma

Si te hacen una pregunta que NO est√° relacionada con estos temas, debes responder amablemente:
"Lo siento, solo puedo ayudarte con informaci√≥n sobre rutas locales y el uso de esta plataforma. 
¬øHay algo espec√≠fico sobre lugares locales que te gustar√≠a saber?"

S√© amable, conciso y √∫til en tus respuestas."""
```

### **Cambiar el Modelo:**
En `chatbot/views.py`, l√≠nea 41:
```python
model = genai.GenerativeModel('gemini-2.5-flash')
# Cambia a:
# model = genai.GenerativeModel('gemini-2.5-pro')  # M√°s potente
# model = genai.GenerativeModel('gemini-2.0-flash') # M√°s estable
```

### **Ajustar Par√°metros:**
```python
generation_config = {
    "temperature": 0.7,      # Creatividad (0.0 - 1.0)
    "top_p": 0.8,           # Diversidad de respuestas
    "top_k": 40,            # N√∫mero de tokens considerados
    "max_output_tokens": 500, # Longitud m√°xima de respuesta
}

response = model.generate_content(
    full_prompt,
    generation_config=generation_config
)
```

---

## üîí **Seguridad**

### **1. API Key:**
- ‚úÖ Guardada en `.env` (no en el c√≥digo)
- ‚úÖ `.env` est√° en `.gitignore`
- ‚úÖ No se expone en el frontend

### **2. Rate Limiting (Recomendado agregar):**
```python
from django.core.cache import cache

# En chat_message view:
user_key = f"chat_rate_{request.user.id}"
request_count = cache.get(user_key, 0)

if request_count >= 10:  # M√°ximo 10 mensajes por minuto
    return Response({
        'error': 'Demasiadas solicitudes. Espera un momento.'
    }, status=status.HTTP_429_TOO_MANY_REQUESTS)

cache.set(user_key, request_count + 1, 60)
```

### **3. Validaci√≥n de Entrada:**
```python
if len(user_message) > 1000:
    return Response({
        'error': 'Mensaje demasiado largo'
    }, status=status.HTTP_400_BAD_REQUEST)
```

---

## üìà **Monitoreo y Logs**

### **Ver uso en Google AI Studio:**
- URL: https://aistudio.google.com/app/apikey
- Click en tu API key
- Ver estad√≠sticas de uso

### **Logs en Django:**
```python
import logging
logger = logging.getLogger(__name__)

# En chat_message:
logger.info(f"Chat request from user {request.user.id}: {user_message[:50]}")
logger.info(f"Chat response length: {len(bot_response)} chars")
```

---

## üêõ **Troubleshooting**

### **Error: "API key not valid"**
```bash
# Verifica que la key est√© en .env
cat .env | grep GEMINI_API_KEY

# Reinicia el servidor Django
python manage.py runserver
```

### **Error: "Resource has been exhausted"**
- Has excedido el rate limit (15 req/min)
- Espera 1 minuto y vuelve a intentar
- Considera agregar rate limiting

### **Error: "Model not found"**
```python
# Lista modelos disponibles:
python -c "import google.generativeai as genai; import os; from dotenv import load_dotenv; load_dotenv(); genai.configure(api_key=os.getenv('GEMINI_API_KEY')); [print(m.name) for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]"
```

### **El bot responde en ingl√©s:**
Agrega al system prompt:
```python
"IMPORTANTE: Responde SIEMPRE en espa√±ol."
```

---

## üöÄ **Mejoras Futuras (Opcionales)**

### **1. Mantener Contexto de Conversaci√≥n:**
```python
# Obtener √∫ltimos 5 mensajes
previous_messages = ChatHistory.objects.filter(
    session_id=session_id
).order_by('-created_at')[:5]

# Construir historial
conversation_history = ""
for msg in reversed(previous_messages):
    conversation_history += f"Usuario: {msg.message}\nAsistente: {msg.response}\n\n"

full_prompt = f"{system_prompt}\n\nHistorial:\n{conversation_history}\nUsuario: {user_message}\n\nAsistente:"
```

### **2. Integrar con Base de Datos:**
```python
from api.models import LocalRoute

# Buscar lugares relevantes
routes = LocalRoute.objects.filter(name__icontains=search_term)[:5]
routes_info = "\n".join([f"- {r.name}: {r.description}" for r in routes])

system_prompt += f"\n\nLugares disponibles:\n{routes_info}"
```

### **3. Soporte Multimodal (Im√°genes):**
```python
# Si el usuario sube una imagen:
import PIL.Image

img = PIL.Image.open('lugar.jpg')
response = model.generate_content([user_message, img])
```

### **4. Streaming de Respuestas:**
```python
response = model.generate_content(full_prompt, stream=True)

for chunk in response:
    if chunk.text:
        yield chunk.text  # Enviar palabra por palabra
```

---

## ‚úÖ **Checklist de Implementaci√≥n**

- [x] API Key de Gemini configurada en `.env`
- [x] `google-generativeai` instalado
- [x] Backend actualizado para usar Gemini
- [x] Frontend actualizado con endpoint correcto
- [x] Modelo `gemini-2.5-flash` configurado
- [x] System prompt personalizado
- [x] Historial de chat en base de datos
- [x] Manejo de errores implementado
- [x] Script de prueba creado
- [ ] Rate limiting agregado (opcional)
- [ ] Contexto de conversaci√≥n (opcional)
- [ ] Integraci√≥n con lugares de la BD (opcional)

---

## üìû **Recursos √ötiles**

- **Google AI Studio:** https://aistudio.google.com/
- **Documentaci√≥n Gemini:** https://ai.google.dev/docs
- **Playground:** https://aistudio.google.com/prompts/new_chat
- **Precios y L√≠mites:** https://ai.google.dev/pricing
- **Gu√≠as de Gemini:** https://ai.google.dev/gemini-api/docs

---

## üéâ **Resultado Final**

El chatbot ahora funciona con **Google Gemini completamente gratis**, sin necesidad de tarjeta de cr√©dito ni preocupaciones por costos. Puede:

‚úÖ Responder preguntas sobre lugares locales
‚úÖ Dar recomendaciones personalizadas
‚úÖ Ayudar a los usuarios con la plataforma
‚úÖ Mantener historial de conversaciones
‚úÖ Rechazar preguntas fuera de contexto
‚úÖ Funcionar para usuarios logueados y no logueados

**¬°El chatbot est√° listo para usar! üöÄ**
